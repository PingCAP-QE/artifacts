#!/usr/bin/env bash
# Code generated by ent, DO NOT EDIT.
set -euo pipefail

function main() {
    local release_ws="build"
    local need_check="false" # true | false
    local need_compose="false" # true | false
    local need_push="false" # true | false
    local result_path="result.yaml"
    parse_arguments "$@"

    if $need_check; then
      pre_check {{.os}} {{.arch}} {{.version}}
    fi
    if $need_compose; then
        compose {{.os}} {{.arch}} {{.version}} "${release_ws}"
    {{- if has .artifactory "package_repo" }}
        if $need_push; then
            push_files "${release_ws}"
            write_push_results "$result_path"
        fi
    {{- end }}
    fi
}

function parse_arguments() {
  while getopts ":w:o:crph" opt; do
    case ${opt} in
      w)
        release_ws=${OPTARG}
        ;;
      o)
        result_path=${OPTARG}
        ;;
      c)
        need_check=true
        ;;
      r)
        need_compose=true
        ;;
      p)
        need_push=true
        ;;
      h)
        print_help
        exit 0
        ;;
      \?)
        echo "Invalid option: -$OPTARG" 1>&2
        exit 1
        ;;
      :)
        echo "Option -$OPTARG requires an argument." 1>&2
        exit 1
        ;;
    esac
  done
  shift $((OPTIND -1))
}

function print_help() {
  echo "Usage: ./your_script.sh [-w RELEASE_WS] [-o RESULT_PATH] [-b] [-h]"
  echo "Options:"
  echo "  -w RELEASE_WS   Set the release workspace path (default: build)"
  echo "  -c              Pre-checking before composing (default: false)"
  echo "  -r              Run the composing (default: false)"
  echo "  -p              Perform a push (default: false)"
  echo "  -o RESULT_PATH  Set the result yaml path (default: result.yaml)"
  echo "  -h              Show this help message"
}

function fetch_file_from_oci_artifact() {
    local destination="$1"
    local to_match_file="$2"
    local repo="$(echo $destination | cut -d ':' -f 1)"

    # get the file blob digest.
    oras manifest fetch $destination | yq --prettyPrint -oy ".layers | filter(.annotations[\"org.opencontainers.image.title\"] | test \"$to_match_file\") | .[0]" >blob.yaml

    # download file
    file="$(yq .annotations[\"org.opencontainers.image.title\"] blob.yaml)"
    blob="$repo@$(yq .digest blob.yaml)"
    oras blob fetch --output $file $blob
    echo "$file"
}

function check_file_in_oci_artifact() {
    local destination="$1"
    local to_match_file="$2"
    local repo="$(echo $destination | cut -d ':' -f 1)"
    oras manifest fetch -o oci_manifest.json $destination

    # get the file blob digest.
    yq -e --prettyPrint -oy ".layers | filter(.annotations[\"org.opencontainers.image.title\"] | test \"$to_match_file\") | length > 0" oci_manifest.json > /dev/null
}

function pre_check() {
{{- range $i, $artifact := .artifacts }}
    echo "🚀 Start pre check before composing {{ .name }} package"
    pre_check_artifact{{ $i }} "$@"
    echo "✅ Finished pre check before composing  {{ .name }} package"
{{ end }}
    echo "✅ All pre checks are done."
}

function compose() {
{{- range $i, $artifact := .artifacts }}
    echo "🚀 Start composing {{ .name }} package"
    compose_artifact{{ $i }} "$@"
    echo "✅ Finished composing  {{ .name }} package"
{{ end }}
    echo "✅ All composings are done."
}

{{- $tiup_mirror := .tiup_mirror }}
{{ range $i, $artifact := .artifacts }}
# Pre check before composing package: {{ $artifact.name }}"
function pre_check_artifact{{ $i }}() {
{{- with $artifact }}
    local os=$1
    local arch=$2
    local version=$3

    {{ $components := .components | jq `map(select(.if != false ))` }}
    ## check online TiUP packages.
    {{- with ($components | jq `map(select(.src.type == "tiup-clone"))`) }}
    tiup mirror set {{ $tiup_mirror }}
    {{- range . }}
    echo -n "🔍 check tiup package: {{ .name }}@{{ .src.version }} in platform $os/$arch."
    {{- if eq .src.version "latest" }}
    tiup list {{ .name }} | grep -E '^v\d+\.\d+\.\d+\s+' | tail -1 | grep -E "($os/$arch|any/any)" > /dev/null && echo " ✅" || { 
      echo " ❌"
      exit 1
    }
    {{- else }}
    tiup list {{ .name }} | grep -E '^{{ .src.version }}\s+' | grep "$os/$arch" > /dev/null && echo " ✅" || { 
      echo " ❌"
      exit 1
    }
    {{- end }}
    {{- end }}
    {{- end }}

    ## check tarballs in oci artifacts.
    {{- range ($components | jq `map(select(.src.type == "oci"))`) }}
    # {{ .name }}
    echo -n "🔍 check file '{{ .name }}' from OCI artifact: {{ .src.url }} -> {{ .src.path }}"
    check_file_in_oci_artifact {{ .src.url }} "{{ .src.path }}" && echo " ✅" || { 
      echo " ❌"
      exit 1
    }
    {{- end }}

    ## check files in remote http sites.
    {{- range ($components | jq `map(select(.src.type == "http"))`) }}
    # {{ .name }}
    echo "check file '{{ .name }}' from remote http url:  {{ .src.url }}"
    wget --spider {{ .src.url }}
    {{- end }}
{{- end }}
}

# Composing package: {{ $artifact.name }}"
function compose_artifact{{ $i }}() {
{{- with $artifact }}
    local os=$1
    local arch=$2
    local version=$3
    local release_ws=$4

    tiup mirror set {{ $tiup_mirror }}
    local archive_dir="{{ .name }}"
    rm -rf "$archive_dir"
    mkdir -p "$archive_dir"

    {{ $components := .components | jq `map(select(.if != false ))` }}
    ## fetch the public pkgs to another mirror.
    {{- with ($components | jq `map(select(.src.type == "tiup-clone"))`) }}
    {{- if gt (. | len)  0 }}
    tiup mirror clone $archive_dir \
    {{- range . }}
    {{ printf "  --%s %s" .name .src.version }} \
    {{- end }}
    --os $os --arch $arch
    {{- end }}
    {{- end }}

    ## self mirror to archive dir.
    tiup mirror set $archive_dir
    tiup_publish_options="--os $os --arch $arch --key $(ls $archive_dir/keys/*-pingcap.json | head -n 1)"

    ## pull tarballs from oci registry and publish to local tiup mirror.
    {{- range ($components | jq `map(select(.src.type == "oci"))`) }}
    # {{ .name }}
    tarball_file=$(fetch_file_from_oci_artifact {{ .src.url }} "{{ .src.path }}")
    {{- if has .src "extract" }}
    tar -zxvf $tarball_file --strip-components={{ math.Sub (strings.Split `/` (default "" .src.extract_inner_path) | len) 1 }} -C $archive_dir {{ default "" .src.extract_inner_path }}
    {{- else if has . "publish" }}
    tiup mirror publish {{ default .name .publish.name }} $version $tarball_file {{ .publish.entrypoint }} ${tiup_publish_options}
    {{- else }}
    mv $tarball_file $archive_dir
    {{- end }}
    {{- end }}

    ## some pkgs need to re-publish
    {{- range ($components | jq `map(select(.src.type == "http"))`) }}
    # {{ .name }}
    wget --tries=3 -c {{ .src.url }}
    {{- if has .src "extract" }}
    tar -zxvf {{ path.Base .src.url }} --strip-components={{ math.Sub (strings.Split `/` (default "" .src.extract_inner_path) | len) 1 }} -C $archive_dir {{ default "" .src.extract_inner_path }}
    {{- else if has . "publish" }}
    tiup mirror publish {{ default .name .publish.name }} $version {{ path.Base .src.url }} {{ .publish.entrypoint }} ${tiup_publish_options}
    {{- else }}
    mv {{ path.Base .src.url }} $archive_dir
    {{- end }}
    {{- end }}

    ## list the tiup packages.
    tiup list --verbose

    ## shrink the size.
    rm -rf $archive_dir/commits

    ## archive it
    mkdir -p "$release_ws"
    local save_file="$release_ws/$archive_dir.tar.gz"
    tar -zcvf "$save_file" $archive_dir
    sha256sum -b "$save_file" | cut -d ' ' -f1 > "$save_file.sha256"
    rm -rf $archive_dir
    echo "sha256sum of '$save_file' is '$(cat $save_file.sha256)'"
{{- end }}
}
{{ end }}

{{- if has .artifactory "package_repo" }}
function prepare_artifact_config() {
    local save_file="$1"

    :> "$save_file"
    yq -p json -o json -i '.["org.opencontainers.image.version"] = "{{ .version }}"' "$save_file"
    yq -p json -o json -i '.["net.pingcap.tibuild.os"] = "{{ .os }}"' "$save_file"
    yq -p json -o json -i '.["net.pingcap.tibuild.architecture"] = "{{ .arch }}"' "$save_file"
    yq -p json -o json -i '.["net.pingcap.tibuild.edition"] = "{{ .edition }}"' "$save_file"
}

function push_files() {
    local release_ws="$1"

    local tag="{{ index .artifactory.tags 0 }}_{{ .os }}_{{ .arch }}"
    local destination="{{ .artifactory.package_repo }}:$tag"

    prepare_artifact_config "$release_ws/artifact-config.json"

    # You should login before call this script, default it use credential with docker `config`` file: ~/.docker/config.json
    # Login steps:
    #   local registry=$(echo "${destination}" | cut -d/ -f)
    #   oras login -u ${ORAS_USER} -p ${ORAS_PASSWD} ${registry}

    pushd "$release_ws"
        oras push --artifact-type application/gzip --config artifact-config.json ${destination}
        {{- range (.artifacts | jq `map(select( .if != false ))`) }}{{ printf " %s.tar.gz" .name }}{{- end }}
        {{- range (.artifacts | jq `map(select( .if != false ))`) }}{{ printf " %s.tar.gz.sha256" .name }}{{- end }}
    popd

    {{- $tag_suffix := printf "_%s_%s" .os .arch -}}
    {{ $more_tags := (.artifactory.tags | jq `.[1:]`) }}
    {{ if gt (len $more_tags) 0 }}
    # add other tags.
    oras tag "${destination}" {{ range $more_tags }}{{ printf " %s%s" . $tag_suffix }}{{ end }}
    {{- end }}
}

function write_push_results() {
    local result_file="$1"
    local tag="{{ index .artifactory.tags 0 }}_{{ .os }}_{{ .arch }}"
    local destination="{{ .artifactory.package_repo }}:$tag"

    # You should login before call this script, default it use credential with docker `config`` file: ~/.docker/config.json
    # Login steps:
    #   local registry=$(echo "${destination}" | cut -d/ -f)
    #   oras login -u ${ORAS_USER} -p ${ORAS_PASSWD} ${registry}
    digest="$(oras discover "${destination}" --distribution-spec v1.1-referrers-tag --format tree | cut -d@ -f2)"

    cat <<EOF > "$result_file"
oci:
  repo: {{ .artifactory.package_repo }}
  tag: "$tag"
  digest: "$digest"
files:
  {{- range (.artifacts | jq `map(select( .if != false ))`) }}
  {{ printf "- %s.tar.gz" .name }}
  {{ printf "- %s.tar.gz.sha256" .name }}
  {{- end }}
EOF
}
{{- end }}

##############################################################################
###### Call the main function with the arguments passed to the script ########
main "$@"

#!/bin/sh
# Code generated by gomplate, DO NOT EDIT.

# It needs kaniko and oras tools, but it can be run in different containers for seperated stages.
# kaniko: https://github.com/GoogleContainerTools/kaniko/blob/main/README.md
# oras: https://oras.land/docs/category/oras-commands/

set -exo pipefail

main() {
  parse_arguments "$@"

  # Access variables directly within the main function
  mkdir -p "${RELEASE_WS}"
  RELEASE_WS=$(realpath "${RELEASE_WS}")

  if [ "$NEED_BUILD_BIN" = "true" ]; then
    build_binaries
  fi

  if [ "$NEED_PUSH_IMAGE" = "true" ]; then
    digests_file="$RELEASE_WS/digests.txt"
    build_and_push_images "${RELEASE_WS}" "$digests_file" "${KANIKO_EXECUTOR}"
    write_push_results "${PUSH_RESULT_SAVE_FILE}" "$digests_file"
  fi

  # push other tags
  if [ "$NEED_TAG_MORE" = "true" ]; then
    add_more_tags
  fi

  echo "✅ All done"
}

parse_arguments() {
  RELEASE_WS="build"
  NEED_BUILD_BIN="false" # Default value is false
  NEED_PUSH_IMAGE="true" # Default value is true
  NEED_TAG_MORE="false" # Default value is false
  NEED_COLLECT_MULT_ARCH="false" # Default value is false
  KANIKO_EXECUTOR="/kaniko/executor"
  PUSH_RESULT_SAVE_FILE="result-images.yaml"

  while [ "$#" -gt 0 ]; do
    case "$1" in
      -w)
        RELEASE_WS="$2"
        shift 2
        ;;
      -b)
        NEED_BUILD_BIN="true"
        shift
        ;;
      -p)
        NEED_PUSH_IMAGE="true"
        shift
        ;;
      -P)
        NEED_PUSH_IMAGE="false"
        shift
        ;;
      -t)
        NEED_TAG_MORE="true"
        shift
        ;;
      -m)
        NEED_COLLECT_MULT_ARCH="true"
        shift
        ;;
      -k)
        KANIKO_EXECUTOR="$2"
        shift 2
        ;;
      -o)
        PUSH_RESULT_SAVE_FILE="$2"
        shift 2
        ;;
      -h)
        print_help
        exit 0
        ;;
      *)
        echo "Invalid option: $1" 1>&2
        exit 1
        ;;
    esac
  done
}

print_help() {
  echo "Usage: script_name [-w release_ws] [-b] [-k kaniko_executor]"
  echo "Options:"
  echo "  -w release_ws       Set the release workspace (default: 'build')"
  echo "  -o result_path      Set the result path (default: 'result-images.yaml')"
  echo "  -b                  Enable building binaries (default false)"
  echo "  -p                  Enable build and push images (default true)"
  echo "  -P                  Skip build and push images (default true)"
  echo "  -t                  Enable add more tags, else just pushed for first tag (default false)"
  echo "  -m                  Enable collect and push multi-arch images (default false)"
  echo "  -k kaniko_executor  Set the Kaniko executor path (default: '/kaniko/executor')"
  echo "  -h                  Print this help message"
}

# >>>>>>>>>>>>>>>> build binaries steps >>>>>>>>>>>>>>>>
build_binaries() {
  {{- $root := . -}}
  {{- if .steps }}{{- range .steps }}
  {{- if or (not (has . "os")) (eq .os $root.os) }}
{{ .script | indent 4 }}
  {{- end }}
  {{- end }}
  echo "building finished."
  {{- else }}
  echo "🏃 Skip: no build steps."
  {{- end }}
}

build_and_push_images() {
    release_ws="$1"
    digests_file="$2"
    kaniko_executor="$3"

    ################# build and push image ################
    tag="{{ index .artifactory.tags 0 }}{{ if ne .profile "release" }}-{{ .profile }}{{ end }}_{{ .os }}_{{ .arch }}"
    kaniko_global_options="--cleanup --cache=false --label net.pingcap.tibuild.new=yes --label net.pingcap.tibuild.git-sha={{.git.sha}}"
    :> "$digests_file"
{{ range (.artifacts | jq `map(select(.type == "image" and .if != false))`) }}
    # >>>>>>>>>>>>>>>> image: {{ .name }} >>>>>>>>>>>>>>>>
    archive_dir="$release_ws/tmp-$(date +%s)"
    mkdir -p "$archive_dir"
    destination="{{ .artifactory.repo }}:$tag"
    digest_file="${archive_dir}/digest.txt"
    kaniko_options="$kaniko_global_options --destination=${destination} --digest-file=${digest_file}"

    {{- if has . "build_args" }}
    {{- range .build_args }}
    kaniko_options="$kaniko_options --build-arg {{.}}"
    {{- end }}
    {{- end }}

    {{- if has . "target" }}
    kaniko_options="$kaniko_options --target {{.target}} --skip-unused-stages"
    {{- end }}

{{- if has . "context" }}
    # just build it with native build from git repo's dockerfile
    $kaniko_executor $kaniko_options --context {{ .context }} --dockerfile {{ .dockerfile }}
{{- else }}

    # Prepare build context for image building.
    echo "Prepare build context for image: $destination ..."
    {{- $files := (.files | jq `map(select(.if != false ))`) -}}
    {{- $localFiles := ($files | jq `map(select(.src.type == "local" or .src.type == null))`) -}}
    {{- $ociFiles := $files | jq `map(select(.src.type == "oci"))` -}}
    {{- $httpFiles := $files | jq `map(select(.src.type == "http"))` -}}
    {{ test.Assert "Can not pull oci artifacts in kaniko container" (eq (len $ociFiles) 0) }}

    {{- if gt (len $localFiles) 0 }}
    ## local files
    {{- range $localFiles }}
    # - {{ .name }}
    mkdir -p "$(dirname ${archive_dir}/{{ .name }})"
    {{- if has .src "extract" }}
      {{- if strings.HasSuffix ".tar.gz" .src.path }}
    tar -zxvf {{ .src.path }} --strip-components={{ math.Sub (strings.Split `/` (default "" .src.extract_inner_path | strings.TrimSuffix "/") | len) 1 }} -C $archive_dir {{ default "" .src.extract_inner_path }}
      {{- else if strings.HasSuffix ".zip" .src.path }}
    unzip -j {{ .src.path }} {{ default "" .src.extract_inner_path }} -d $archive_dir
      {{- else }}
        {{ fail "Unsupported archive format, only support .tar.gz and .zip" }}
      {{- end }}
      {{- if and (has .src "extract_inner_path") (ne (path.Base .src.extract_inner_path) .name) }}
    mv $archive_dir/{{ path.Base .src.extract_inner_path }} ${archive_dir}/{{ .name }}
      {{- end }}
    {{- else }}
    cp -r {{ .src.path }} ${archive_dir}/{{ .name }}
    {{- end }}
    {{- end }}
    {{- end }}

    {{- if gt (len $httpFiles) 0 }}
    ## compose files from http.
    {{- range $httpFiles }}
    # {{ .name }}
    wget --tries=3 -c {{ .src.url }}
    mkdir -p $(dirname ${archive_dir}/{{ .name }})
    {{- if has .src "extract" }}
      {{- if strings.HasSuffix ".tar.gz" .src.url }}
    tar -zxvf {{ path.Base .src.url }} --strip-components={{ math.Sub (strings.Split `/` (default "" .src.extract_inner_path | strings.TrimSuffix "/") | len) 1 }} -C $archive_dir {{ default "" .src.extract_inner_path }}
      {{- else if strings.HasSuffix ".zip" .src.url }}
    unzip -j {{ path.Base .src.url }} {{ default "" .src.extract_inner_path }} -d $archive_dir
      {{- else }}
        {{ fail "Unsupported archive format, only support .tar.gz and .zip" }}
      {{- end }}
      {{- if and (has .src "extract_inner_path") (ne (path.Base .src.extract_inner_path) .name) }}
    mv $archive_dir/{{ path.Base .src.extract_inner_path }} ${archive_dir}/{{ .name }}
      {{- end }}
    {{- else }}
    cp -r {{ path.Base .src.url }} ${archive_dir}/{{ .name }}
    {{- end }}
    {{- end }}
    {{- end }}
    ## build and push
    dockerfile="{{ .dockerfile }}"
    # get dockerfile from url if the `.dockerfile` value is a http url.
    if [ "${dockerfile#https://}" != "$dockerfile" ] || [ "${dockerfile#http://}" != "$dockerfile" ]; then
        echo "URL starts with https:// or http://, now I will download it and save it into: '$archive_dir/Dockerfile'."
        wget --tries=3 -c -O "$archive_dir/Dockerfile" "$dockerfile"
        dockerfile="$archive_dir/Dockerfile"
    fi
    dockerfile="$(realpath $dockerfile)"

    $kaniko_executor $kaniko_options --context="$archive_dir" --dockerfile="$dockerfile"
{{- end }}

    # Save digest file path for later use
    awk 1 "$digest_file" >> "$digests_file"
    echo "Pushed image: $destination"
    rm -rf $archive_dir
    # <<<<<<<<<<<<<<<< image: {{ .name }} <<<<<<<<<<<<<<<<
{{ end }}
    # All pushed.
    echo "✅ Pushed digests recorded in file: $digests_file"
    cat "$digests_file"
}

{{- $tag_suffix := "" }}
{{- if ne .profile "release" }}
{{- $tag_suffix = printf "-%s" .profile }}
{{- end }}
{{- $platform_tag_suffix := printf "%s_%s_%s" $tag_suffix .os .arch }}

{{- $base_tags := coll.Slice }}
{{- range $index, $tag := .artifactory.tags }}
{{- $base_tags = append (printf "%s%s" $tag $tag_suffix) $base_tags }}
{{- end }}

{{- $tags := coll.Slice }}
{{- range $index, $tag := $base_tags }}
{{- $tags = append (printf "%s%s" $tag $platform_tag_suffix) $tags }}
{{- end }}

# Write results to file.
write_push_results() {
    result_file="$1"
    input_disgests_file="$2"

    primary_tag="{{ index $tags 0 }}"
    cat <<EOF > "$result_file"
images:
{{- range $index, $image := (.artifacts | jq `map(select(.type == "image" and .if != false))`) }}
- repo: {{ $image.artifactory.repo }}
  url: "{{ $image.artifactory.repo }}:$primary_tag"
  tag: "$primary_tag"
  digest: '$(sed -n "{{ add $index 1 }}p" $input_disgests_file)'
{{- end }}
EOF
}

add_more_tags() {
    {{- if gt (len $tags) 1 }}
    # add other tags.
    {{- range $index, $image := (.artifacts | jq `map(select(.type == "image" and .if != false))`) }}
    oras tag {{ $image.artifactory.repo }}:{{ join $tags " " }}
    {{- end }}
    {{- else }}
    echo "🤷 No more tags need to be taged."
    {{- end }}
}

collect_and_push_multi_arch_images() {
    {{- $self_tag := index $tags 0 }}
    {{- $other_arch := ternary "arm64" "amd64" (eq .arch "amd64") }}
    {{- $other_tag := printf "%s_%s_%s" (index $base_tags 0) .os $other_arch }}

    {{- range $index, $image := (.artifacts | jq `map(select(.type == "image" and .if != false))`) }}

    # 📦 try to collect and push multi-arch image: {{ $image.artifactory.repo }}:{{ index $base_tags 0 }}
        {{- range $i, $tag := $base_tags }}
            {{- if eq $i 0 }}
    if ! crane digest {{ $image.artifactory.repo }}:{{ $other_tag }}; then
        echo "🤷 Image {{ $image.artifactory.repo }}:{{ $other_tag }} not found."
        exit 0
    fi
    crane index append -m {{ $image.artifactory.repo }}:{{ $self_tag }} -m {{ $image.artifactory.repo }}:{{ $other_tag }} -t {{ $image.artifactory.repo }}:{{ $tag }}
            {{- else }}
    crane tag {{ $image.artifactory.repo }}:{{ index $base_tags 0 }} {{ $tag }}
            {{- end }}
        {{- end }}
    {{- end }}
}

main "$@"

#!/bin/sh
# Code generated by gomplate, DO NOT EDIT.

# It needs kaniko and oras tools, but it can be run in different containers for seperated stages.

set -exo pipefail

main() {
  parse_arguments "$@"

  # Access variables directly within the main function
  mkdir -p "${RELEASE_WS}"
  RELEASE_WS=$(realpath "${RELEASE_WS}")

  if [ "$NEED_BUILD_BIN" = "true" ]; then
    build_binaries
  fi

  if [ "$NEED_PUSH_IMAGE" = "true" ]; then
    digests_file="$RELEASE_WS/digests.txt"
    build_and_push_images "${RELEASE_WS}" "$digests_file" "${KANIKO_EXECUTOR}"
    write_push_results "${PUSH_RESULT_SAVE_FILE}" "$digests_file"
  fi

  # push other tags
  if [ "$NEED_TAG_MORE" = "true" ]; then
    add_more_tags
  fi

  echo "✅ All done"
}

parse_arguments() {
  RELEASE_WS="build"
  NEED_BUILD_BIN="false" # Default value is false
  NEED_PUSH_IMAGE="true" # Default value is true
  NEED_TAG_MORE="false" # Default value is false
  KANIKO_EXECUTOR="/kaniko/executor"
  PUSH_RESULT_SAVE_FILE="result-images.yaml"

  while [ "$#" -gt 0 ]; do
    case "$1" in
      -w)
        RELEASE_WS="$2"
        shift 2
        ;;
      -b)
        NEED_BUILD_BIN="true"
        shift
        ;;
      -p)
        NEED_PUSH_IMAGE="true"
        shift
        ;;
      -P)
        NEED_PUSH_IMAGE="false"
        shift
        ;;
      -t)
        NEED_TAG_MORE="true"
        shift
        ;;
      -k)
        KANIKO_EXECUTOR="$2"
        shift 2
        ;;
      -o)
        PUSH_RESULT_SAVE_FILE="$2"
        shift 2
        ;;
      -h)
        print_help
        exit 0
        ;;
      *)
        echo "Invalid option: $1" 1>&2
        exit 1
        ;;
    esac
  done
}

print_help() {
  echo "Usage: script_name [-w release_ws] [-b] [-k kaniko_executor]"
  echo "Options:"
  echo "  -w release_ws       Set the release workspace (default: 'build')"
  echo "  -o result_path      Set the result path (default: 'result-images.yaml')"
  echo "  -b                  Enable building binaries (default false)"
  echo "  -p                  Enable build and push images (default true)"
  echo "  -P                  Skip build and push images (default true)"
  echo "  -t                  Enable add more tags, else just pushed for first tag (default false)"
  echo "  -k kaniko_executor  Set the Kaniko executor path (default: '/kaniko/executor')"
  echo "  -h                  Print this help message"
}

# >>>>>>>>>>>>>>>> build binaries steps >>>>>>>>>>>>>>>>
build_binaries() {
  {{- $root := . -}}
  {{- if .steps }}{{- range .steps }}
  {{- if or (not (has . "os")) (eq .os $root.os) }}
{{ .script | indent 4 }}
  {{- end }}
  {{- end }}
  echo "building finished."
  {{- else }}
  echo "🏃 Skip: no build steps."
  {{- end }}
}

build_and_push_images() {
    release_ws="$1"
    digests_file="$2"
    kaniko_executor="$3"

    ################# build and push image ################
    tag="{{ index .artifactory.tags 0 }}{{ if ne .profile "release" }}-{{ .profile }}{{ end }}_{{ .os }}_{{ .arch }}"
    :> "$digests_file"
{{ range (.artifacts | jq `map(select(.type == "image" and .if != false))`) }}
    # >>>>>>>>>>>>>>>> image: {{ .name }} >>>>>>>>>>>>>>>>
    archive_dir="$release_ws/tmp-$(date +%s)"
    mkdir -p "$archive_dir"
    destination="{{ .artifactory.repo  }}:$tag"
    digest_file="${archive_dir}/digest.txt"
    kaniko_executor_global_options="--cleanup --cache=false --destination=${destination} --digest-file=${digest_file} --label net.pingcap.tibuild.new=yes"
    {{- if has . "build_args" }}
    {{- range .build_args }}
    kaniko_executor_global_options="$kaniko_executor_global_options --build-arg {{.}}"
    {{- end }}
    {{- end }}

{{- if has . "context" }}
    # just build it with native build from git repo's dockerfile
    $kaniko_executor $kaniko_executor_global_options --context {{ .context }} --dockerfile {{ .dockerfile }}
{{- else }}

    # Prepare build context for image building.
    echo "Prepare build context for image: $destination ..."
    {{- $files := (.files | jq `map(select(.if != false ))`) -}}
    {{- $localFiles := ($files | jq `map(select(.src.type == "local" or .src.type == null))`) -}}
    {{- $ociFiles := $files | jq `map(select(.src.type == "oci"))` -}}
    {{- $httpFiles := $files | jq `map(select(.src.type == "http"))` -}}
    {{ test.Assert "Can not pull oci artifacts in kaniko container" (eq (len $ociFiles) 0) }}

    {{- if gt (len $localFiles) 0 }}
    ## local files
    {{- range $localFiles }}
    # - {{ .name }}
    mkdir -p "$(dirname ${archive_dir}/{{ .name }})"
    {{- if has .src "extract" }}
    tar -zxvf {{ .src.path }} --strip-components={{ math.Sub (strings.Split `/` (default "" .src.extract_inner_path | strings.TrimSuffix "/") | len) 1 }} -C $archive_dir {{ default "" .src.extract_inner_path }}
      {{- if and (has .src "extract_inner_path") (ne (path.Base .src.extract_inner_path) .name) }}
    mv $archive_dir/{{ path.Base .src.extract_inner_path }} ${archive_dir}/{{ .name }}
      {{- end }}
    {{- else }}
    cp -r {{ .src.path }} ${archive_dir}/{{ .name }}
    {{- end }}
    {{- end }}
    {{- end }}

    {{- if gt (len $httpFiles) 0 }}
    ## compose files from http.
    {{- range $httpFiles }}
    # {{ .name }}
    wget {{ .src.url }}
    mkdir -p $(dirname ${archive_dir}/{{ .name }})
    {{- if has .src "extract" }}
    tar -zxvf {{ path.Base .src.url }} --strip-components={{ math.Sub (strings.Split `/` (default "" .src.extract_inner_path | strings.TrimSuffix "/") | len) 1 }} -C $archive_dir {{ default "" .src.extract_inner_path }}
      {{- if and (has .src "extract_inner_path") (ne (path.Base .src.extract_inner_path) .name) }}
    mv $archive_dir/{{ path.Base .src.extract_inner_path }} ${archive_dir}/{{ .name }}
      {{- end }}
    {{- else }}
    cp -r {{ path.Base .src.url }} ${archive_dir}/{{ .name }}
    {{- end }}
    {{- end }}
    {{- end }}
    ## build and push
    dockerfile="{{ .dockerfile }}"
    # get dockerfile from url if the `.dockerfile` value is a http url.
    if [ "${dockerfile#https://}" != "$dockerfile" ] || [ "${dockerfile#http://}" != "$dockerfile" ]; then
        echo "URL starts with https:// or http://, now I will download it and save it into: '$archive_dir/Dockerfile'."
        wget "$dockerfile" -O "$archive_dir/Dockerfile"
        dockerfile="$archive_dir/Dockerfile"
    fi
    dockerfile="$(realpath $dockerfile)"

    $kaniko_executor $kaniko_executor_global_options --context="$archive_dir" --dockerfile="$dockerfile"
{{- end }}

    # Save digest file path for later use
    awk 1 "$digest_file" >> "$digests_file"
    echo "Pushed image: $destination"
    rm -rf $archive_dir
    # <<<<<<<<<<<<<<<< image: {{ .name }} <<<<<<<<<<<<<<<<
{{ end }}
    # All pushed.
    echo "✅ Pushed digests recorded in file: $digests_file"
    cat "$digests_file"
}

# Write results to file.
write_push_results() {
    result_file="$1"
    input_disgests_file="$2"

    tag="{{ index .artifactory.tags 0 }}{{ if ne .profile "release" }}-{{ .profile }}{{ end }}_{{ .os }}_{{ .arch }}"

    cat <<EOF > "$result_file"
images:
{{- range $index, $image := (.artifacts | jq `map(select(.type == "image" and .if != false))`) }}
- repo: {{ $image.artifactory.repo  }}
  url: "{{ $image.artifactory.repo  }}:$tag"
  tag: "$tag"
  digest: '$(sed -n "{{ add $index 1 }}p" $input_disgests_file)'
{{- end }}
EOF
}

add_more_tags() {
    {{- $tag_suffix := printf "_%s_%s" .os .arch }}
    {{- if ne .profile "release" }}
    {{- $tag_suffix = printf "-%s_%s_%s" .profile .os .arch }}
    {{- end }}

    {{- $tags := coll.Slice }}
    {{- range $index, $tag := .artifactory.tags }}
    {{- $tags = append (printf "%s%s" $tag $tag_suffix) $tags }}
    {{- end }}

    {{- if gt (len $tags) 1 }}
    # add other tags.
    {{- range $index, $image := (.artifacts | jq `map(select(.type == "image" and .if != false))`) }}
    oras tag {{ $image.artifactory.repo  }}:{{ join $tags " " }}
    {{- end }}
    {{- else }}
    echo "🤷 No more tags need to be taged."
    {{- end }}
}

main "$@"
